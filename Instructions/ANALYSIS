Report on the Neural Network Model


Overview of the analysis: Explain the purpose of this analysis.

The purpose of the analysis is to predict if applicants funded by Alphabet Soup will be successful. Applicants success was predicted by creating a binary classifier.


Results: Using bulleted lists and images to support your answers, address the following questions.



Data Preprocessing

What variable(s) are considered the target(s) for your model?
- Target varibale column "IS_SUCCESSFUL". If funding is successful 1, if funding is not sucessful 0.


What variable(s) are considered to be the features for your model?

- Features include 
- APPLICATION_TYPE            
- AFFILIATION                
- CLASSIFICATION              
- USE_CASE                     
- ORGANIZATION                
- STATUS                       
- INCOME_AMT                  
- SPECIAL_CONSIDERATIONS       
- ASK_AMT      
What variable(s) are neither targets nor features, and should be removed from the input data?

Columns removed include 'EIN' and 'Name'


Compiling, Training, and Evaluating the Model

How many neurons, layers, and activation functions did you select for your neural network model?

The accuracy of the model was below the target rate specified in the project which is 75%. The best result received for accuracy was 72.6%


Were you able to achieve the target model performance?
What steps did you take to try and increase model performance?

No, I was unable to achieve the target model performance. Achieved 72.6%

-First hidden layer
units = 43, activation = 'relu' , input_dim = 43 

- Second hidden layer
units = 43, activation = 'relu' , input_dim = 43 

-Third hidden layer
units = 43, activation = 'relu' , input_dim = 43 

- Output layer
units = 1, activation = 'sigmoid'

The numbers of units in the hidden layers was changed for the optimization models but none of them acheived 75% as specified in the project requirements


Summary
Deep learning can have multiple hidden layers and large enough number of neurons with the right number of activation functions in order to reach the accuary for binary classification models.

